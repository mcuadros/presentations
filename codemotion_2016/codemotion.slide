Analyzing 900 million commits with Go
Codemotion - 19 Nov 2016

Máximo Cuadros
VP of Engineering at source{d}

mcuadros@gmail.com
https://github.com/mcuadros
@mcuadros_

* A bit of context

* The goal

- Repository discovery = *find*the*clone*URLs*
- Cloning 17.991.286 repositories = *saving*the*repositories*
- Analyzing the repositories = *identify*who*is*doing*what*

* Ok, but why? ... because of source{d}


* What is source{d}

- Our main goal is to *understand*the*FOSS*
- We *analyze* the content of *Git* repositories
- We *monetize* through *recruitment* (our engineering team at source{d} is hired using our method)

* Ok, and why with Go ...

* Go is ..

- Simple and minimalist language, *easy*to*learn*
- *Fast*to*code* like Python, Ruby or PHP, but also *fast*to*execute* like Java
- *Concurrency* is a built-in feature



*source{d}* has been written in Go since its first day

* How we did this at source{d}

* Phase #1: Repository discovery

* The available resources

We needed the entrypoints of the repositories *all*over*the*world*, so we explored
the available resources:

- *GitHub*Archive*, is a project collecting GH API events since 2011
- *GHTorrent*, same but since 2013, but they have alternative formats
- *GitHub*Data*, official GitHub dataset with 2.8 million repositories

Nothing about other sources like BitBucket, Gitlab, etc.

* So ... we went directly to the source

We retrieve the URL from the repositories from *different*SaaS* as:

- *GitHub* - 17M repositories* - [[http://github.com/google/go-github][github.com/google/go-github.com]]
- *BitBucket* - 150k repositories*
- and more coming such as GitLab, CodePlex, etc.
.caption *public repositories, not including forks


Finally, we also *crawl* the web looking for *self-hosted* services using _cgit_



* Phase #2: Cloning 17.991.286 repositories

* Cloning 1 repository requires:

- Retrieving all the available *git*objects* from the remote. In [[http://shafiulazam.com/gitbook/7_the_packfile.html][packfile]] format.

- The packfile format is *compressed* and *deltified*. Random access requires a full scan, so we need to *build*a*index*.

- Also we need to store other relevant information as: *references* (branches, tags, etc), *remotes* and *configuration*

#The process of storing and index generation is done in parallel with goroutines, to avoid read the file being written

* .git anatomy

 .git
 ├── config
 ├── HEAD
 ├── objects
 │   ├── info
 │   └── pack
 │       ├── pack-34e2a300f8de20e6bff25834a5dd696c991714b7.idx
 │       └── pack-34e2a300f8de20e6bff25834a5dd696c991714b7.pack
 └── refs
     ├── heads
     │   └── master
     ├── remotes
     │   └── origin
     │       └── HEAD
     └── tags

* Cloning ALL the repositories in the world requires ... a distributed filesystem

* Using a distributed filesystem


Working in a distributed filesystem is great because you have *unlimited*space** but  we *can't* simply store the *spare*files* of a _.git_ folder.

We need to do this in an *efficient*way* ...

- ideally, *one*file* per repository
- *update* without writing the full file
- *seek* over any file

.caption *if you can pay for it


* Can we use zip, tar or any other archive format?

* ZIP format and his limitations:


- You *can't*modify* the ZIP file
- Knowing the *size* foreach file is *required* before start to write 

.image assets/zip-64.png _ 750

* Our own archive format: śiva format

: We evaluated many archive formats such as: _zip_, _tar_, _har_, etc.
: None of them fitted our requirements, so we created our *own*format*, of course with *Go*.

- *Constant-time* random file access
- *Seekable*access* to the contained files
- *Concatenable* archive files
- and of course it is *open*source* - [[https://github.com/src-d/go-siva][github.com/src-d/go-siva]]

.image assets/siva.png 220 _

* Using siva at Google Cloud Storage

.image assets/siva_pull.png _ 820

* Phase #3: Analyzing the repositories

* Let's read the commits, easy ... or not?

* Extracting 967.345.715 commits

The commits are *contained* in the packfiles, along with other many useful objects:

- Commit
- Tree
- Blob
- Tag
- OFS Delta
- REF Delta

The first 4 object types are *well-known* by all of us, but the last two are *internal* to the packfile format. The deltas are the method used by git to *save*space*

* git object model

.image assets/objects-example.png 530 _
.caption Image from "Git Community Book" - http://shafiulazam.com/gitbook/index.html"

* Handling git from Go

git is compounded of many different protocols, formats and algorithms. That's why not many languages have available a native implementation.

Available native libraries:

- *libgit2*, pure _C_, the most widely used and wrapped in dozens of languages, including Go
- *jgit*, pure _Java_, used by Eclipse, Gerrit, and many others

In Go:

- *git2go*, wrap of _libgit2_, it is the most complete implementation

and many partial and abandoned implementations.

* go-git, a pure Go git implementation

- Dependency free, *pure*Go*, without any C dependency
- Highly extensible, following *open/close*principle*
- *new*v4* aims to be a replacement of *git2go*. for reading

.image assets/go-git.png 200 _


*but*why?*
We can perform more *low*level*operations* than with other libraries. It was also extremely useful to improve our knowledge about *git*internals*. And a good opportunity to contribute to the community.

* Now we have the commits, what about the changes ...

* Calculating the diff

Some people may think that Git only stores the changes, but this is not true, every *commit*is*a*snapshot* of the full tree.

When *git*diff* executes the diff between the files' contents - between the commit target, by current HEAD, and the previous on - it *calculates*it*on*the*fly*.

.image assets/space.png 100 _

The diff calculation is made with the *longest*common*subsequence* algorithm, and this is a *NP-hard* problem.


* So let's find something faster

* Calculating the diff of the tree, is faster

The *changed*files* can be identified *comparing* the the *tree* of the commit with the tree from his parent.
.image assets/tree1.svg _ 700

* Result of the comparision 
.image assets/tree2.svg _ 800

* In what languages?

* Detecting the language of 1.131.056.665 files

The language detection can be archive using [[https://github.com/github/linguist][*linguist*]] a library created by GitHub. Linguist is used to create the famous bar:
.image assets/languages.png _ 1000

Detection is done by:

- Extension
- Language disambiguation

*simple-linguist*, is our port to _Go_ of the original _Ruby_ library, with fewer precisions in arcane languages but with an improved *performance*of*100x*

* Questions?

